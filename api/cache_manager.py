"""
Ø³ÛŒØ³ØªÙ… Ú©Ø´ÛŒÙ†Ú¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ API
Ù†Ø³Ø®Ù‡ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Render.com
"""

import time
import threading
from typing import Any, Optional, Dict, Callable
import hashlib
import json
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class TradingCache:
    """Ú©Ø´ Ù…Ø®ØµÙˆØµ ØªØ±ÛŒØ¯ÛŒÙ†Ú¯ - thread-safe Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(TradingCache, cls).__new__(cls)
                cls._instance._initialize()
        return cls._instance
    
    def _initialize(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ú©Ø´"""
        self.cache: Dict[str, Dict] = {}
        self.hits = 0
        self.misses = 0
        self.max_size = 300  # Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Render (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø§ÙØ¸Ù‡)
        self.default_ttl = {
            'market_data': 25,      # 25 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø²Ø§Ø±
            'analysis': 45,         # 45 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
            'ichimoku': 90,         # 1.5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ
            'signals': 15,          # 15 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
            'overview': 60,         # 1 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ
        }
        self.cleanup_interval = 300  # Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡ ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ
        self.last_cleanup = time.time()
        logger.info("âœ… Ø³ÛŒØ³ØªÙ… Ú©Ø´ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯ (Max: %s items)", self.max_size)
    
    def _make_key(self, func_name: str, *args, **kwargs) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú©Ù„ÛŒØ¯ ÛŒÚ©ØªØ§ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§"""
        key_parts = [func_name]
        key_parts.extend(str(arg) for arg in args)
        key_parts.extend(f"{k}:{v}" for k, v in sorted(kwargs.items()))
        key_string = "_".join(key_parts)
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² hash Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        return f"{func_name[:10]}_{hashlib.md5(key_string.encode()).hexdigest()[:12]}"
    
    def _auto_cleanup(self):
        """ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡"""
        now = time.time()
        if now - self.last_cleanup < self.cleanup_interval:
            return
        
        keys_to_delete = []
        for key, entry in self.cache.items():
            if now > entry['expires']:
                keys_to_delete.append(key)
        
        for key in keys_to_delete:
            del self.cache[key]
        
        if keys_to_delete:
            logger.debug(f"ğŸ§¹ {len(keys_to_delete)} Ø¢ÛŒØªÙ… Ù…Ù†Ù‚Ø¶ÛŒ Ø§Ø² Ú©Ø´ Ø­Ø°Ù Ø´Ø¯")
        
        self.last_cleanup = now
    
    def get(self, key: str) -> Optional[Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ú©Ø´ Ø¨Ø§ ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±"""
        self._auto_cleanup()
        
        if key in self.cache:
            entry = self.cache[key]
            if time.time() < entry['expires']:
                self.hits += 1
                return entry['data']
            else:
                del self.cache[key]
        
        self.misses += 1
        return None
    
    def set(self, key: str, data: Any, ttl: Optional[int] = None, func_type: str = 'default'):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†Ø¯Ø§Ø²Ù‡"""
        if ttl is None:
            ttl = self.default_ttl.get(func_type, 30)
        
        # Ø§Ú¯Ø± Ú©Ø´ Ù¾Ø± Ø§Ø³ØªØŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ø­Ø°Ù Ú©Ù†
        if len(self.cache) >= self.max_size:
            self._remove_oldest(5)  # 5 ØªØ§ Ø§Ø² Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ†â€ŒÙ‡Ø§
        
        self.cache[key] = {
            'data': data,
            'expires': time.time() + ttl,
            'created': time.time(),
            'type': func_type,
            'size': len(str(data)) if isinstance(data, (str, dict, list)) else 1
        }
    
    def _remove_oldest(self, count: int = 1):
        """Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§"""
        if not self.cache:
            return
        
        # Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù† Ø§ÛŒØ¬Ø§Ø¯
        sorted_items = sorted(self.cache.items(), key=lambda x: x[1]['created'])
        
        for i in range(min(count, len(sorted_items))):
            key, _ = sorted_items[i]
            del self.cache[key]
        
        logger.debug(f"ğŸ—‘ï¸ {count} Ø¢ÛŒØªÙ… Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø² Ú©Ø´ Ø­Ø°Ù Ø´Ø¯")
    
    def cached(self, ttl: Optional[int] = None, func_type: str = 'default'):
        """Ø¯Ú©ÙˆØ±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ú©Ø´ Ú©Ø±Ø¯Ù† ØªÙˆØ§Ø¨Ø¹"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                # ØªÙˆÙ„ÛŒØ¯ Ú©Ù„ÛŒØ¯
                cache_key = self._make_key(func.__name__, *args, **kwargs)
                
                # Ú†Ú© Ú©Ø´
                cached_result = self.get(cache_key)
                if cached_result is not None:
                    if isinstance(cached_result, dict):
                        cached_result['_cached'] = True
                        cached_result['_cache_hit'] = True
                        cached_result['_cache_key'] = cache_key
                    return cached_result
                
                # Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
                result = func(*args, **kwargs)
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
                if result is not None:
                    self.set(cache_key, result, ttl, func_type)
                    if isinstance(result, dict):
                        result['_cached'] = False
                        result['_cache_hit'] = False
                        result['_cache_key'] = cache_key
                
                return result
            return wrapper
        return decorator
    
    def get_stats(self) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„ Ú©Ø´"""
        self._auto_cleanup()
        
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªÙ‚Ø±ÛŒØ¨ÛŒ Ú©Ø´
        total_size = sum(entry.get('size', 1) for entry in self.cache.values())
        
        # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
        type_counts = {}
        type_sizes = {}
        
        for entry in self.cache.values():
            t = entry['type']
            type_counts[t] = type_counts.get(t, 0) + 1
            type_sizes[t] = type_sizes.get(t, 0) + entry.get('size', 1)
        
        # Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¢ÛŒØªÙ…
        oldest_age = 0
        if self.cache:
            oldest = min(self.cache.values(), key=lambda x: x['created'])
            oldest_age = time.time() - oldest['created']
        
        return {
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate_percent': round(hit_rate, 2),
            'current_size': len(self.cache),
            'max_size': self.max_size,
            'total_size_bytes': total_size,
            'type_distribution': type_counts,
            'type_sizes': type_sizes,
            'oldest_item_seconds': round(oldest_age, 1),
            'cleanup_last': round(time.time() - self.last_cleanup, 1)
        }
    
    def clear(self, func_type: Optional[str] = None):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ø´"""
        if func_type:
            keys_to_delete = [
                k for k, v in self.cache.items() 
                if v['type'] == func_type
            ]
            for key in keys_to_delete:
                del self.cache[key]
            logger.info(f"Ú©Ø´ Ù†ÙˆØ¹ '{func_type}' Ù¾Ø§Ú© Ø´Ø¯ ({len(keys_to_delete)} Ø¢ÛŒØªÙ…)")
        else:
            self.cache.clear()
            logger.info("ØªÙ…Ø§Ù…ÛŒ Ú©Ø´ Ù¾Ø§Ú© Ø´Ø¯")
        
        return True

# Singleton instance - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø³Ø§Ù†
cache = TradingCache()

# Ø¯Ú©ÙˆØ±Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù
market_data_cached = cache.cached(ttl=25, func_type='market_data')
analysis_cached = cache.cached(ttl=45, func_type='analysis')
ichimoku_cached = cache.cached(ttl=90, func_type='ichimoku')
signal_cached = cache.cached(ttl=15, func_type='signals')
overview_cached = cache.cached(ttl=60, func_type='overview')
general_cached = cache.cached(ttl=30, func_type='default')

# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ endpointÙ‡Ø§
def endpoint_cache_key(request, func_name: str) -> str:
    """ØªÙˆÙ„ÛŒØ¯ Ú©Ù„ÛŒØ¯ Ú©Ø´ Ø¨Ø±Ø§ÛŒ endpointÙ‡Ø§ÛŒ FastAPI"""
    from fastapi import Request
    
    if not isinstance(request, Request):
        return f"endpoint_{func_name}"
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² path Ùˆ query parameters Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯
    path = request.url.path
    params = dict(request.query_params)
    
    key_parts = [func_name, path]
    key_parts.extend(f"{k}:{v}" for k, v in sorted(params.items()))
    
    key_string = "_".join(key_parts)
    return hashlib.md5(key_string.encode()).hexdigest()[:16]